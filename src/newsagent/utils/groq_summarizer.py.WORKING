# ── src/newsagent/utils/groq_summarizer.py ───────────────────────────────
"""
summarize_long_transcript(text, …) → str

• Free-tier friendly:  GROQ_PAUSE_SEC  (default 10 s) after every success
  + global back-off after any 429.
• If Groq replies 413 (payload too large) the chunk is halved and retried.
"""

from __future__ import annotations
import math, os, random, re, time, threading
from typing import List
import requests

ENDPOINT = "https://api.groq.com/openai/v1/chat/completions"
MODEL    = "llama3-8b-8192"
RATE_LIMIT_SEC = float(os.getenv("GROQ_PAUSE_SEC", "10"))
MAX_BYTES      = int(os.getenv("GROQ_MAX_BYTES", "150_000"))

_next_allowed = 0.0                      # global throttle
_lock         = threading.Lock()

_HEADERS = lambda k: {"Authorization": f"Bearer {k}",
                      "Content-Type": "application/json"}
_BOILER  = re.compile(r"^\s*(summary\s*:|here\s+is\s+a\s+.*)", re.I)


# ── helpers ──────────────────────────────────────────────────────────────
def _post(payload: dict, key: str, retries: int = 5) -> str:
    """One Groq call with 429 handling plus global pacing."""
    global _next_allowed
    for att in range(retries):
        with _lock:
            wait_left = max(0.0, _next_allowed - time.time())
        if wait_left:
            time.sleep(wait_left)

        r = requests.post(ENDPOINT, json=payload,
                          headers=_HEADERS(key), timeout=90)

        if r.status_code == 429:
            back = 5 + 2 * (att + 1)            # linear back-off
            with _lock:
                _next_allowed = time.time() + back
            print(f"   Groq 429 – retry {att+1}/{retries} (sleep {back}s)…")
            time.sleep(back)
            continue

        if r.status_code == 413:
            raise RuntimeError("413")

        r.raise_for_status()
        with _lock:
            _next_allowed = time.time() + RATE_LIMIT_SEC
        return r.json()["choices"][0]["message"]["content"]

    raise RuntimeError("too many retries")


def _clean(txt: str) -> str:
    return "\n".join(l for l in (_BOILER.sub("", ln) for ln in txt.splitlines())
                     if l.strip())


def _chunk_words(words: List[str]) -> List[str]:
    """Split into UTF-8 chunks ≤ MAX_BYTES."""
    out, buf = [], []
    for w in words:
        buf.append(w)
        if len(" ".join(buf).encode()) > MAX_BYTES:
            buf.pop()
            out.append(" ".join(buf))
            buf = [w]
    if buf:
        out.append(" ".join(buf))
    return out


# ── public API ───────────────────────────────────────────────────────────
def summarize_long_transcript(
    transcript: str,
    api_key: str | None = None,
    *,
    model: str = MODEL,
    words_per_chunk: int = 80,
) -> str:
    key = api_key or os.getenv("GROQ_API_KEY") or ""
    if not key:
        raise RuntimeError("GROQ_API_KEY missing")

    chunks = _chunk_words(transcript.split())
    partials: List[str] = []

    for idx, chunk in enumerate(chunks, 1):
        tgt = max(120, min(700,
                 words_per_chunk * math.ceil(len(chunk.split()) / 8000 * 100)))
        prompt = ("You are a precise analyst. Summarise the following transcript "
                  f"in ≈{tgt} words. Use bullet points where helpful and keep all "
                  "important numbers, names, and causal links. NO intro header.")
        print(f"    Summarising chunk {idx}/{len(chunks)} …")

        attempt, cur = 0, chunk
        while True:
            attempt += 1
            try:
                txt = _post({
                    "model": model,
                    "messages": [
                        {"role": "system", "content": prompt},
                        {"role": "user",   "content": cur},
                    ]}, key)
                break
            except RuntimeError as e:
                if str(e) != "413" or attempt >= 3:
                    raise
                cur = " ".join(cur.split()[: len(cur.split()) // 2])
                print("      413 – chunk halved, retrying…")

        partials.append(_clean(txt))

    if len(partials) == 1:
        return partials[0]

    merged = _post({
        "model": model,
        "messages": [
            {"role": "system",
             "content": "Merge the partial summaries into one coherent ≈600-word briefing (no duplication)."},
            {"role": "user", "content": "\n\n".join(partials)},
        ]}, key)
    return _clean(merged)
